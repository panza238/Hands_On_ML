{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c1f945-e193-44b4-8754-8e24810c28b9",
   "metadata": {},
   "source": [
    "# Chapter 07 - Ensemble Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca465f-7102-4c07-9661-b57783e0466a",
   "metadata": {},
   "source": [
    "## Voting Classifiers\n",
    "Muchos algoritmos (idealmente, que cometen errores distintos.) que predicen sobre una misma instancia. El output del Voting Classifier es la instancia más votada}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693039f7-3858-42cf-95f1-7d73b056bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f2adb7-a591-4bfa-a5d0-6f254a8929fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "voting='hard')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6b41fc-8d03-46bb-9d99-78abeac8792a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.87\n",
      "RandomForestClassifier 0.98\n",
      "SVC 0.975\n",
      "VotingClassifier 0.975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59c7d2-ca8b-4981-8a2e-8506031db9e4",
   "metadata": {},
   "source": [
    "#### Bueno... no se ve tanto acá. Pero en el libro se ve que el VotingClassifier funciona mejor que cada uno de los clasificadores independientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fbf11b-58ba-4fde-aa49-07c519f4f4f7",
   "metadata": {},
   "source": [
    "## Bagging Classifier - _Bootsrap Aggregating Classifiers_\n",
    "Básicamente, entrenan el mismo algoritmo con diferentes subsets del training set: bagging = Con reposición. pasting = Sin reposición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fecf4b0-ef82-4591-b751-982db49734a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edb121-ccdf-478e-b6f5-510a65785cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d5cf6-d6a8-4a98-a835-b019bab74859",
   "metadata": {},
   "source": [
    "Ok... 96%... not bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d955d0-b91b-435e-872b-ccf04e4190c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-bag (oob) evaluation\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1,\n",
    "    oob_score=True  # Setteo oob=True\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22824967-2e0d-4b59-acd3-0a26b89a0efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_samples=100,\n",
       "                  n_estimators=500, n_jobs=-1, oob_score=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9d8785-b6c9-4742-9bbe-ce8894739bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7200864c-27e1-411e-8905-58040e434cad",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3f74fb-1c63-498d-a9a0-ff30e4c60e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba69c1-87a4-4bab-83cd-df55e79c5bd8",
   "metadata": {},
   "source": [
    "It is equivalent to use Bagging Classifier with Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "595a79e9-2996-4bb1-8630-a1368f2269d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.08942630642540082\n",
      "sepal width (cm) 0.021051918647736402\n",
      "petal length (cm) 0.4295513027005101\n",
      "petal width (cm) 0.45997047222635273\n"
     ]
    }
   ],
   "source": [
    "# Also, they show feature importance\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rf_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "\n",
    "for name, score in zip(iris[\"feature_names\"], rf_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a95aa-e008-41e2-93ab-ee729f173239",
   "metadata": {},
   "source": [
    "OK. Seems that petal width is the most important feature in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3ca062-b366-4c36-95d4-64bc250737a4",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "351e7694-ca7a-4d19-80ac-fc323fdb512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost: Los modelos se entrenan secuencialmente (en serie). Cada modelo se enfoca en clasificar bien los errores del modelo anterior\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa639e3d-b237-4715-8708-14b744aff64c",
   "metadata": {},
   "source": [
    "### Gradient Boosting: Mismo concepto. Entrenamiento secuencial. Pero se enfoca en el error residual del modelo previo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0203083f-ae89-4573-b967-aefb48c96d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero un gradient boosting a mano:\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Semilla. Paso 1\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)\n",
    "# Paso 2\n",
    "y2 = y - tree_reg1.predict(X)  # Este es el error residual! delta(y, y_hat)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)\n",
    "# Paso 3\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y3)\n",
    "\n",
    "# Hasta acá tengo los 3 modelos creados\n",
    "# Ahora hago las predicciones sumando las predicciones de los 3 classifiers\n",
    "X_new = X[:3]  # Simulo nuevas observaciones\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df68a1f3-3771-4bf2-b0d9-86a2125499c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04982003, 0.11290391, 0.94094906])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce5d5bfe-9e55-4b23-bf3f-1237a4b12bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Esto equivale a:\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "027ea6d9-8392-4b65-a2d0-fed3518b9150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=113)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "errors = [mean_squared_error(y_val, y_pred)for y_pred in gbrt.staged_predict(X_val)]\n",
    "\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b379ce-6440-47e6-80c7-0c9409e499c4",
   "metadata": {},
   "source": [
    "OK... el error mínimo lo encontró en 113 estimators, cuando el máximo era 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bafc05e-59ed-40ea-9dbc-a86498aa7e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping también se puede hacer con warm_start = True \n",
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)  # Warm Start\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:  # Early stop si el validation error no baja en 5 iteraciones consecutivas\n",
    "            break # early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b7f9500-de30-4ebf-a903-f4227b34138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Honorable Mention a XGBoost\n",
    "import xgboost\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47ca2d03-c078-4799-89ce-d3d9d0359a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.36606\n",
      "[1]\tvalidation_0-rmse:0.27278\n",
      "[2]\tvalidation_0-rmse:0.21293\n",
      "[3]\tvalidation_0-rmse:0.17580\n",
      "[4]\tvalidation_0-rmse:0.15112\n",
      "[5]\tvalidation_0-rmse:0.13755\n",
      "[6]\tvalidation_0-rmse:0.12808\n",
      "[7]\tvalidation_0-rmse:0.12427\n",
      "[8]\tvalidation_0-rmse:0.12175\n",
      "[9]\tvalidation_0-rmse:0.12103\n",
      "[10]\tvalidation_0-rmse:0.11930\n",
      "[11]\tvalidation_0-rmse:0.11912\n",
      "[12]\tvalidation_0-rmse:0.12009\n",
      "[13]\tvalidation_0-rmse:0.12249\n",
      "[14]\tvalidation_0-rmse:0.12346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=3)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc36ae-18a3-4806-a11e-d55614aea46d",
   "metadata": {},
   "source": [
    "XGBoost se encarga de hacer el early stopping. En este caso, para cuando el error sube por 3 rondas consecutivas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3749b-9aa0-4155-b3c9-1d083459e6a3",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde75d6-0400-40f8-ba75-3fdba241bf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ho_ml_kernel",
   "language": "python",
   "name": "ho_ml_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
